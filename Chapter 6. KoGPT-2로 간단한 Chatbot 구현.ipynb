{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Chapter 6. KoGPT-2로 간단한 Chatbot 구현.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNeCHZQdIwSQtYFixi9PKn8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["#  KoGPT-2로 간단한 Chatbot 구현"],"metadata":{"id":"3bwFVw9lofIH"}},{"cell_type":"markdown","source":["## 실험준비"],"metadata":{"id":"T7rxAHmelTqk"}},{"cell_type":"markdown","source":["먼저 필요한 자료 가져옵니다.\n","\n","데이터는 lab_tutorial/data에 담아 두었습니다.\n","\n","data는 NSMC data와 Chatbot data가 있습니다.\n","\n","출처: https://github.com/e9t/nsmc, https://github.com/songys/Chatbot_data"],"metadata":{"id":"Cw1FZld3RvCI"}},{"cell_type":"code","source":["!git clone https://github.com/momozzing/lab_tutorial.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D2-WvYxzMJAG","executionInfo":{"status":"ok","timestamp":1642680240829,"user_tz":-540,"elapsed":2089,"user":{"displayName":"모모찡","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhXYN7KGIQ82T3UxGI5PqrDXj-_-btC890XdlDY6Q=s64","userId":"05085778681463631947"}},"outputId":"c3c9303f-6bfb-4f76-8295-68c853c0d34b"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'lab_tutorial'...\n","remote: Enumerating objects: 17, done.\u001b[K\n","remote: Counting objects: 100% (17/17), done.\u001b[K\n","remote: Compressing objects: 100% (12/12), done.\u001b[K\n","remote: Total 17 (delta 3), reused 14 (delta 3), pack-reused 0\u001b[K\n","Unpacking objects: 100% (17/17), done.\n"]}]},{"cell_type":"markdown","source":["필요한 라이브러리들을 설치합니다. \n","\n","pandas, torch, tqdm, tansformers, KoBERT, sentenvepiece"],"metadata":{"id":"NPCF0lQGSDXb"}},{"cell_type":"code","source":["%cd lab_tutorial\n","!mkdir model_save\n","!pip install -r requirements.txt\n","!pip install 'git+https://github.com/SKTBrain/KoBERT.git#egg=kobert_tokenizer&subdirectory=kobert_hf'\n","%pip install sentencepiece\n","!pip install pandas==1.1.0                # 버전 충돌때문에 downgrade했습니다. "],"metadata":{"id":"d5PEJRzRNG7u","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1642680262191,"user_tz":-540,"elapsed":21365,"user":{"displayName":"모모찡","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhXYN7KGIQ82T3UxGI5PqrDXj-_-btC890XdlDY6Q=s64","userId":"05085778681463631947"}},"outputId":"aeb64d53-60dc-48a5-84e0-3b923e13409a"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/lab_tutorial/lab_tutorial\n","Collecting pandas==1.3.2\n","  Using cached pandas-1.3.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n","Requirement already satisfied: torch==1.8.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.8.0)\n","Requirement already satisfied: tqdm==4.62.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (4.62.1)\n","Requirement already satisfied: transformers==4.9.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (4.9.2)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.3.2->-r requirements.txt (line 1)) (2.8.2)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.3.2->-r requirements.txt (line 1)) (1.19.5)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.3.2->-r requirements.txt (line 1)) (2018.9)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0->-r requirements.txt (line 2)) (3.10.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.9.2->-r requirements.txt (line 4)) (2019.12.20)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.9.2->-r requirements.txt (line 4)) (21.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.9.2->-r requirements.txt (line 4)) (4.10.0)\n","Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers==4.9.2->-r requirements.txt (line 4)) (0.0.12)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.9.2->-r requirements.txt (line 4)) (0.10.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.9.2->-r requirements.txt (line 4)) (2.23.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.9.2->-r requirements.txt (line 4)) (0.0.47)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.9.2->-r requirements.txt (line 4)) (6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.9.2->-r requirements.txt (line 4)) (3.4.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.9.2->-r requirements.txt (line 4)) (3.0.6)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas==1.3.2->-r requirements.txt (line 1)) (1.15.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.9.2->-r requirements.txt (line 4)) (3.7.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.9.2->-r requirements.txt (line 4)) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.9.2->-r requirements.txt (line 4)) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.9.2->-r requirements.txt (line 4)) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.9.2->-r requirements.txt (line 4)) (3.0.4)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.9.2->-r requirements.txt (line 4)) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.9.2->-r requirements.txt (line 4)) (1.1.0)\n","Installing collected packages: pandas\n","  Attempting uninstall: pandas\n","    Found existing installation: pandas 1.1.0\n","    Uninstalling pandas-1.1.0:\n","      Successfully uninstalled pandas-1.1.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-colab 1.0.0 requires pandas~=1.1.0; python_version >= \"3.0\", but you have pandas 1.3.2 which is incompatible.\u001b[0m\n","Successfully installed pandas-1.3.2\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["pandas"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Collecting kobert_tokenizer\n","  Cloning https://github.com/SKTBrain/KoBERT.git to /tmp/pip-install-cg_8re6g/kobert-tokenizer_e9621a3a971b4270bc5d3e5694461024\n","  Running command git clone -q https://github.com/SKTBrain/KoBERT.git /tmp/pip-install-cg_8re6g/kobert-tokenizer_e9621a3a971b4270bc5d3e5694461024\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3021, in _dep_map\n","    return self.__dep_map\n","  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2815, in __getattr__\n","    raise AttributeError(attr)\n","AttributeError: _DistInfoDistribution__dep_map\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/base_command.py\", line 180, in _main\n","    status = self.run(options, args)\n","  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/req_command.py\", line 199, in wrapper\n","    return func(self, options, args)\n","  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/commands/install.py\", line 385, in run\n","    conflicts = self._determine_conflicts(to_install)\n","  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/commands/install.py\", line 515, in _determine_conflicts\n","    return check_install_conflicts(to_install)\n","  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/operations/check.py\", line 103, in check_install_conflicts\n","    package_set, _ = create_package_set_from_installed()\n","  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/operations/check.py\", line 45, in create_package_set_from_installed\n","    package_set[name] = PackageDetails(dist.version, dist.requires())\n","  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2736, in requires\n","    dm = self._dep_map\n","  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3023, in _dep_map\n","    self.__dep_map = self._compute_dependencies()\n","  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3033, in _compute_dependencies\n","    reqs.extend(parse_requirements(req))\n","  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3094, in parse_requirements\n","    yield Requirement(line)\n","  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3115, in __init__\n","    str(self.marker) if self.marker else None,\n","  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/packaging/markers.py\", line 316, in __str__\n","    return _format_marker(self._markers)\n","  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/packaging/markers.py\", line 176, in _format_marker\n","    return _format_marker(marker[0])\n","  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/packaging/markers.py\", line 185, in _format_marker\n","    return \" \".join([m.serialize() for m in marker])\n","  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/packaging/markers.py\", line 185, in <listcomp>\n","    return \" \".join([m.serialize() for m in marker])\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/pip3\", line 8, in <module>\n","    sys.exit(main())\n","  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/main.py\", line 71, in main\n","    return command.main(cmd_args)\n","  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/base_command.py\", line 104, in main\n","    return self._main(args)\n","  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/base_command.py\", line 212, in _main\n","    logger.critical(\"Operation cancelled by user\")\n","KeyboardInterrupt\n","Collecting pandas==1.1.0\n","  Using cached pandas-1.1.0-cp37-cp37m-manylinux1_x86_64.whl (10.5 MB)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.1.0) (2.8.2)\n","Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas==1.1.0) (1.19.5)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas==1.1.0) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas==1.1.0) (1.15.0)\n","Installing collected packages: pandas\n","  Attempting uninstall: pandas\n","    Found existing installation: pandas 1.3.2\n","    Uninstalling pandas-1.3.2:\n","      Successfully uninstalled pandas-1.3.2\n","Successfully installed pandas-1.1.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["pandas"]}}},"metadata":{}}]},{"cell_type":"markdown","source":["## Fine-tuning "],"metadata":{"id":"zXJOKVKilZFv"}},{"cell_type":"markdown","source":["이제 시작입니다. \n","\n","필요한 라이브러리들 import합니다."],"metadata":{"id":"mbnnymQFSY5R"}},{"cell_type":"code","source":["from argparse import ArgumentParser\n","import pandas as pd\n","import os\n","import torch\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","from transformers import AutoTokenizer, AutoModelWithLMHead\n","from torch.optim import AdamW"],"metadata":{"id":"NdKTQugypOrQ","executionInfo":{"status":"ok","timestamp":1642680262191,"user_tz":-540,"elapsed":4,"user":{"displayName":"모모찡","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhXYN7KGIQ82T3UxGI5PqrDXj-_-btC890XdlDY6Q=s64","userId":"05085778681463631947"}}},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":["tokenizer와 model을 define합니다.\n","\n","생성 모델임으로 AutoModelWithLMHead를 사용합니다. \n","\n","Auto는 허깅페이스 내에 올라가있는 모델이 GPT-2모델이면 자동으로 GPT-2모델을 넣어줍니다. (BERT면 자동으로 BERT로)\n","\n","GPT2LMHeadModel 쓰셔도 됩니다."],"metadata":{"id":"VmV694VBnJop"}},{"cell_type":"code","source":["os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"                      ## 에러 계속 뜨는것 방지 https://github.com/kakaobrain/pororo/issues/69 참고 \n","\n","tokenizer = AutoTokenizer.from_pretrained(\"skt/kogpt2-base-v2\")\n","SPECIAL_TOKENS = {                                       ## special token을 정의합니다. \n","    \"bos_token\": \"<bos>\",\n","    \"eos_token\": \"<eos>\",\n","    \"pad_token\": \"<pad>\",\n","    \"sep_token\": \"<seq>\"\n","    }\n","SPECIAL_TOKENS_VALUES = [\"<bos>\", \"<eos>\", \"<pad>\", \"<seq>\"]\n","tokenizer.add_special_tokens(SPECIAL_TOKENS)            ## tokenizer(Vocab)에 special token을 추가합니다. \n","\n","model = AutoModelWithLMHead.from_pretrained(\n","    \"skt/kogpt2-base-v2\"\n",").cuda()\n","\n","model.resize_token_embeddings(len(tokenizer))        ## vocab size를 늘렸으니 임베딩 차원도 같이 늘립니다. "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9ruxA7OapOnf","executionInfo":{"status":"ok","timestamp":1642680269807,"user_tz":-540,"elapsed":7619,"user":{"displayName":"모모찡","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhXYN7KGIQ82T3UxGI5PqrDXj-_-btC890XdlDY6Q=s64","userId":"05085778681463631947"}},"outputId":"4e09b3ad-1cad-4000-8772-c1dc50450e09"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","/usr/local/lib/python3.7/dist-packages/transformers/models/auto/modeling_auto.py:902: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n","  FutureWarning,\n"]},{"output_type":"execute_result","data":{"text/plain":["Embedding(51204, 768)"]},"metadata":{},"execution_count":26}]},{"cell_type":"markdown","source":["데이터 불러옵니다.\n","\n","컬럼마다 data를 쪼개서 value만 넣어둡니다.\n","\n","ChatbotData.csv에는 11823 개의 데이터가 있음으로 10000개를 Train data로 사용합니다."],"metadata":{"id":"A7HQTxHJn__t"}},{"cell_type":"code","source":["train_data = pd.read_csv(\"data/ChatbotData.csv\", delimiter=\",\")\n","print(train_data)\n","train_data = train_data[:10000]\n","train_text, train_labels = (\n","    train_data[\"Q\"].values,\n","    train_data[\"A\"].values,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wc0iZRq6pOf7","executionInfo":{"status":"ok","timestamp":1642684527132,"user_tz":-540,"elapsed":314,"user":{"displayName":"모모찡","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhXYN7KGIQ82T3UxGI5PqrDXj-_-btC890XdlDY6Q=s64","userId":"05085778681463631947"}},"outputId":"95dc6bc3-6112-496b-b672-70b6bb08a2f2"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["                             Q                         A  label\n","0                       12시 땡!                하루가 또 가네요.      0\n","1                  1지망 학교 떨어졌어                 위로해 드립니다.      0\n","2                 3박4일 놀러가고 싶다               여행은 언제나 좋죠.      0\n","3              3박4일 정도 놀러가고 싶다               여행은 언제나 좋죠.      0\n","4                      PPL 심하네                눈살이 찌푸려지죠.      0\n","...                        ...                       ...    ...\n","11818           훔쳐보는 것도 눈치 보임.        티가 나니까 눈치가 보이는 거죠!      2\n","11819           훔쳐보는 것도 눈치 보임.             훔쳐보는 거 티나나봐요.      2\n","11820              흑기사 해주는 짝남.                    설렜겠어요.      2\n","11821  힘든 연애 좋은 연애라는게 무슨 차이일까?  잘 헤어질 수 있는 사이 여부인 거 같아요.      2\n","11822               힘들어서 결혼할까봐        도피성 결혼은 하지 않길 바라요.      2\n","\n","[11823 rows x 3 columns]\n"]}]},{"cell_type":"markdown","source":["text의 maxlenght를 찾습니다."],"metadata":{"id":"zRQWUpYTophb"}},{"cell_type":"code","source":["len_check = []\n","for i in range(len(train_data[:10000])):\n","  len_check.append(len(train_data[\"Q\"][i])+len(train_data['A'][i]))\n","print(max(len_check))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d9PFHYosoYt-","executionInfo":{"status":"ok","timestamp":1642684612244,"user_tz":-540,"elapsed":324,"user":{"displayName":"모모찡","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhXYN7KGIQ82T3UxGI5PqrDXj-_-btC890XdlDY6Q=s64","userId":"05085778681463631947"}},"outputId":"7c8e3b48-ed12-42a2-926e-4ab54c55257d"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["79\n"]}]},{"cell_type":"markdown","source":["DataLoader에 넣기 위해 dataset을 정의해줍니다.\n","\n","User turn에 <usr\\> , system turn에 <sys\\>, 끝에는 끝을 알리는 <eos\\> 토큰들을 넣습니다"],"metadata":{"id":"-MFzLlrXpGM4"}},{"cell_type":"code","source":["dataset = [\n","    {\"data\": \"<usr>\" + t + \"<sys>\" + l + str(tokenizer.eos_token), \"label\": l}\n","    for t, l in zip(train_text, train_labels)\n","]"],"metadata":{"id":"SFJSXgl8o6XG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["dataloader를 정의합니다. \n","\n","참고 https://subinium.github.io/pytorch-dataloader/"],"metadata":{"id":"KJGjysnsdlrs"}},{"cell_type":"code","source":["train_loader = DataLoader(\n","    dataset,\n","    batch_size=64,\n","    num_workers=2,\n","    drop_last=True,\n","    pin_memory=True,\n",")"],"metadata":{"id":"IFNGDqhjo6Nm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["validation data도 똑같이 진행합니다. \n","\n","validation data은 ChatbotData.csv에 11823 개의 데이터가 있음으로 1,823개를 Train data로 사용합니다."],"metadata":{"id":"SBVVTAOadtoL"}},{"cell_type":"code","source":["eval_data = pd.read_csv(\"data/ChatbotData.csv\", delimiter=\",\")\n","eval_data = eval_data[10000:]\n","eval_text, eval_labels = (\n","    eval_data[\"Q\"].values,\n","    eval_data[\"A\"].values,\n",")\n","dataset = [\n","    {\"data\": \"<usr>\" + t + \"<sys>\" + l + str(tokenizer.eos_token), \"label\": l}\n","    for t, l in zip(eval_text, eval_labels)\n","]\n","eval_loader = DataLoader(\n","    dataset,\n","    batch_size=64,\n","    num_workers=2,\n","    drop_last=True,\n","    pin_memory=True,\n",")"],"metadata":{"id":"jBfClYTCpONN","executionInfo":{"status":"ok","timestamp":1642680269807,"user_tz":-540,"elapsed":10,"user":{"displayName":"모모찡","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhXYN7KGIQ82T3UxGI5PqrDXj-_-btC890XdlDY6Q=s64","userId":"05085778681463631947"}}},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":["optimizer는 ADAMW를 사용합니다."],"metadata":{"id":"0Eat_0d0d5fM"}},{"cell_type":"code","source":["optimizer = AdamW(params=model.parameters(),\n","    lr=3e-5, weight_decay=3e-7\n",")"],"metadata":{"id":"lNofQx6erLJw","executionInfo":{"status":"ok","timestamp":1642680269808,"user_tz":-540,"elapsed":10,"user":{"displayName":"모모찡","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhXYN7KGIQ82T3UxGI5PqrDXj-_-btC890XdlDY6Q=s64","userId":"05085778681463631947"}}},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":["train, validation step입니다.\n","\n","GPT-2의 Casual Attention은 LMHead안에 정의되어있습니다. \n","Auto Regressive loss도 잘 정의되어 있습니다. \n","\n","참고: https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/gpt2/modeling_gpt2.py#L943"],"metadata":{"id":"ZG19M8ZR82Ht"}},{"cell_type":"code","source":["epochs = 10\n","for epoch in range(epochs):\n","    model.train()\n","    for train in tqdm(train_loader):\n","        optimizer.zero_grad()\n","        text, label = train[\"data\"], train[\"label\"]\n","        text_tokens = tokenizer(\n","            text,\n","            return_tensors=\"pt\",\n","            max_length=80,\n","            truncation=True,\n","            padding=True,\n","        )\n","\n","        input_ids = text_tokens.input_ids.cuda()\n","        # print(input_ids)\n","        # print(tokenizer.convert_ids_to_tokens(input_ids[0]))         ## 토크나이저가 어떻게 자르고 어떻게 구성되있는지 보기. \n","        attention_mask = text_tokens.attention_mask.cuda()            ## <pad>토큰들은 자동으로 masking되어서 실제 단어만 들어있는것만 학습 진행. \n","\n","        output = model.forward(\n","            input_ids=input_ids,\n","            attention_mask=attention_mask,\n","            labels=input_ids,\n","        )\n","\n","        loss = output.loss\n","        loss.backward()        \n","        optimizer.step()\n","\n","    print({\"loss\": loss.item()})\n","\n","    with torch.no_grad():\n","        model.eval()\n","        for eval in tqdm(eval_loader):\n","            eval_text, eval_label = eval[\"data\"], eval[\"label\"]\n","            eval_text_tokens = tokenizer(\n","                eval_text,\n","                return_tensors=\"pt\",\n","                max_length=80,\n","                truncation=True,\n","                padding=True,\n","            )\n","\n","            input_ids = eval_text_tokens.input_ids.cuda()\n","            attention_mask = eval_text_tokens.attention_mask.cuda()\n","\n","            eval_out = model.forward(\n","                input_ids=input_ids,\n","                attention_mask=attention_mask,\n","                labels=input_ids,\n","            )\n","    \n","            eval_loss = eval_out.loss\n","\n","        print({\"eval_loss\": eval_loss.item()})          \n","        print({\"epoch\": epoch+1})\n","        torch.save(model.state_dict(), f\"model_save/GPT-2_fintuing-{epoch+1}.pt\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DyEIubgRrLBr","executionInfo":{"status":"ok","timestamp":1642682726518,"user_tz":-540,"elapsed":2388585,"user":{"displayName":"모모찡","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhXYN7KGIQ82T3UxGI5PqrDXj-_-btC890XdlDY6Q=s64","userId":"05085778681463631947"}},"outputId":"643be6af-0a6d-485c-f6ab-1dcf3734d8ce"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 156/156 [01:13<00:00,  2.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'loss': 2.179687261581421}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  6.00it/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'eval_loss': 2.319176435470581}\n","{'epoch': 1}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 156/156 [01:13<00:00,  2.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'loss': 1.9928951263427734}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  5.99it/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'eval_loss': 2.2837932109832764}\n","{'epoch': 2}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 156/156 [01:13<00:00,  2.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'loss': 1.8246866464614868}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  5.99it/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'eval_loss': 2.2864644527435303}\n","{'epoch': 3}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 156/156 [01:13<00:00,  2.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'loss': 1.6810544729232788}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  5.98it/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'eval_loss': 2.3225889205932617}\n","{'epoch': 4}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 156/156 [01:13<00:00,  2.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'loss': 1.543284296989441}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  5.98it/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'eval_loss': 2.361959218978882}\n","{'epoch': 5}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 156/156 [01:13<00:00,  2.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'loss': 1.4081428050994873}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  6.00it/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'eval_loss': 2.414842128753662}\n","{'epoch': 6}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 156/156 [01:13<00:00,  2.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'loss': 1.308071255683899}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  6.01it/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'eval_loss': 2.45314621925354}\n","{'epoch': 7}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 156/156 [01:13<00:00,  2.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'loss': 1.2125298976898193}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  6.00it/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'eval_loss': 2.522562026977539}\n","{'epoch': 8}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 156/156 [01:13<00:00,  2.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'loss': 1.1046844720840454}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  6.01it/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'eval_loss': 2.577317714691162}\n","{'epoch': 9}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 156/156 [01:13<00:00,  2.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'loss': 0.9929193258285522}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  5.99it/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'eval_loss': 2.6324028968811035}\n","{'epoch': 10}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 156/156 [01:13<00:00,  2.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'loss': 0.9611718058586121}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  6.01it/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'eval_loss': 2.651136636734009}\n","{'epoch': 11}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 156/156 [01:13<00:00,  2.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'loss': 0.9222537279129028}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  6.01it/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'eval_loss': 2.6684093475341797}\n","{'epoch': 12}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 156/156 [01:13<00:00,  2.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'loss': 0.8374670743942261}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  5.99it/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'eval_loss': 2.69752836227417}\n","{'epoch': 13}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 156/156 [01:13<00:00,  2.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'loss': 0.7923844456672668}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  6.00it/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'eval_loss': 2.7094879150390625}\n","{'epoch': 14}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 156/156 [01:13<00:00,  2.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'loss': 0.7222490310668945}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  6.01it/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'eval_loss': 2.7345805168151855}\n","{'epoch': 15}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 156/156 [01:13<00:00,  2.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'loss': 0.6924041509628296}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  6.01it/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'eval_loss': 2.808478832244873}\n","{'epoch': 16}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 156/156 [01:13<00:00,  2.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'loss': 0.648760199546814}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  5.99it/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'eval_loss': 2.807887554168701}\n","{'epoch': 17}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 156/156 [01:13<00:00,  2.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'loss': 0.6188452839851379}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  6.00it/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'eval_loss': 2.8450095653533936}\n","{'epoch': 18}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 156/156 [01:13<00:00,  2.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'loss': 0.5974649786949158}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  6.00it/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'eval_loss': 2.8169596195220947}\n","{'epoch': 19}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 156/156 [01:13<00:00,  2.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'loss': 0.5856381058692932}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  6.00it/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'eval_loss': 2.9057083129882812}\n","{'epoch': 20}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 156/156 [01:13<00:00,  2.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'loss': 0.5671884417533875}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  6.03it/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'eval_loss': 2.8642373085021973}\n","{'epoch': 21}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 156/156 [01:13<00:00,  2.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'loss': 0.5573303699493408}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  6.02it/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'eval_loss': 2.912720203399658}\n","{'epoch': 22}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 156/156 [01:13<00:00,  2.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'loss': 0.5386002063751221}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  5.98it/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'eval_loss': 2.9177703857421875}\n","{'epoch': 23}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 156/156 [01:13<00:00,  2.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'loss': 0.5438969135284424}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  5.99it/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'eval_loss': 2.9552805423736572}\n","{'epoch': 24}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 156/156 [01:13<00:00,  2.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'loss': 0.510629415512085}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  5.98it/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'eval_loss': 2.9575085639953613}\n","{'epoch': 25}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 156/156 [01:12<00:00,  2.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'loss': 0.48692527413368225}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  6.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'eval_loss': 2.9885456562042236}\n","{'epoch': 26}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 156/156 [01:12<00:00,  2.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'loss': 0.4630880057811737}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  6.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'eval_loss': 3.0139570236206055}\n","{'epoch': 27}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 156/156 [01:12<00:00,  2.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'loss': 0.4662376940250397}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  6.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'eval_loss': 3.053097724914551}\n","{'epoch': 28}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 156/156 [01:12<00:00,  2.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'loss': 0.49715864658355713}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  6.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'eval_loss': 3.0584371089935303}\n","{'epoch': 29}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 156/156 [01:12<00:00,  2.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'loss': 0.49904102087020874}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  6.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["{'eval_loss': 3.11588716506958}\n","{'epoch': 30}\n"]}]},{"cell_type":"markdown","source":["## Interactive"],"metadata":{"id":"Cv0wN1QvrYEG"}},{"cell_type":"code","source":["import torch\n","from transformers import AutoModelWithLMHead, AutoTokenizer"],"metadata":{"id":"J3QYU2njrK3z","executionInfo":{"status":"aborted","timestamp":1642680279628,"user_tz":-540,"elapsed":252,"user":{"displayName":"모모찡","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhXYN7KGIQ82T3UxGI5PqrDXj-_-btC890XdlDY6Q=s64","userId":"05085778681463631947"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ckpt_name = \"model_save/GPT-2_fintuing-10.pt\"                       ## check point save file 위치 \n","model = AutoModelWithLMHead.from_pretrained(\"skt/kogpt2-base-v2\")\n","tokenizer = AutoTokenizer.from_pretrained(\"skt/kogpt2-base-v2\")\n","\n","SPECIAL_TOKENS = {\n","    \"bos_token\": \"<bos>\",\n","    \"eos_token\": \"<eos>\",\n","    \"pad_token\": \"<pad>\",\n","    \"sep_token\": \"<seq>\"\n","    }\n","SPECIAL_TOKENS_VALUES = [\"<bos>\", \"<eos>\", \"<pad>\", \"<seq>\"]\n","tokenizer.add_special_tokens(SPECIAL_TOKENS)\n","model.resize_token_embeddings(len(tokenizer)) \n","\n","model.load_state_dict(torch.load(ckpt_name, map_location=\"cpu\"))          ## save point load\n","model.cuda()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IJ8Tme9ZrgyJ","executionInfo":{"status":"ok","timestamp":1642683136046,"user_tz":-540,"elapsed":8811,"user":{"displayName":"모모찡","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhXYN7KGIQ82T3UxGI5PqrDXj-_-btC890XdlDY6Q=s64","userId":"05085778681463631947"}},"outputId":"1ffc5a42-de00-41c0-e22b-c189490a2b35"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/models/auto/modeling_auto.py:902: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n","  FutureWarning,\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"output_type":"execute_result","data":{"text/plain":["GPT2LMHeadModel(\n","  (transformer): GPT2Model(\n","    (wte): Embedding(51204, 768)\n","    (wpe): Embedding(1024, 768)\n","    (drop): Dropout(p=0.1, inplace=False)\n","    (h): ModuleList(\n","      (0): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (1): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (2): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (3): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (4): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (5): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (6): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (7): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (8): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (9): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (10): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (11): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=51204, bias=False)\n",")"]},"metadata":{},"execution_count":34}]},{"cell_type":"markdown","source":["참고\n","\n","https://huggingface.co/docs/transformers/v4.15.0/en/internal/generation_utils\n","\n","https://colab.research.google.com/github/huggingface/blog/blob/master/notebooks/02_how_to_generate.ipynb\n","\n","https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/generation_utils.py#L741"],"metadata":{"id":"djd8cA1PXLnz"}},{"cell_type":"code","source":["with torch.no_grad():\n","    while True:\n","        t = input(\"\\nUser: \")\n","        tokens = tokenizer(\n","            \"<usr>\" + t,\n","            return_tensors=\"pt\",\n","            truncation=True,\n","            padding=True,\n","            max_length=80\n","        )\n","\n","        input_ids = tokens.input_ids.cuda()\n","        attention_mask = tokens.attention_mask.cuda()\n","        sample_output = model.generate(\n","            input_ids, \n","            max_length=80, \n","            num_beams=5, \n","            early_stopping=True\n","        )\n","        gen = sample_output[0]\n","        print(\"System: \" + tokenizer.decode(gen[len(input_ids[0]):-1], skip_special_tokens=True))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"sju7L3WDrguK","executionInfo":{"status":"error","timestamp":1642684160868,"user_tz":-540,"elapsed":44009,"user":{"displayName":"모모찡","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhXYN7KGIQ82T3UxGI5PqrDXj-_-btC890XdlDY6Q=s64","userId":"05085778681463631947"}},"outputId":"3ec6f0cb-ddc1-46f9-9c9f-febba5373e91"},"execution_count":44,"outputs":[{"name":"stdout","output_type":"stream","text":["\n","User: 배고파요\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py:1838: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  next_indices = next_tokens // vocab_size\n"]},{"output_type":"stream","name":"stdout","text":["System: 얼른 맛난 음식 드세요.\n","\n","User: 피곤해요\n","System: 충전하는 시간 그 자체로 소중합니다.\n","\n","User: 집에가고싶어요\n","System: 집이 최고죠.\n","\n","User: 엄마보고싶어요\n","System: 연락드려보세요.\n","\n","User: 피곤해요\n","System: 충전하는 시간 그 자체로 소중합니다.\n","\n","User: 어디살아요?\n","System: 이름, 직업 등 말고 온전히 자신으로 사는 거죠.\n","\n","User: 여행가고싶어요\n","System: 계획을 세워보세요.\n","\n","User: 어이없어요\n","System: 그냥 잊어버리세요.\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    624\u001b[0m         \"\"\"\n\u001b[0;32m--> 625\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: ","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-44-644f6b40fdbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nUser: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         tokens = tokenizer(\n\u001b[1;32m      5\u001b[0m             \u001b[0;34m\"<usr>\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}